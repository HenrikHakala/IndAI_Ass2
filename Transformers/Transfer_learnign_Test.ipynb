{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEaLlS6klcJp"
      },
      "source": [
        "#Image transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-FwZEIett2T3"
      },
      "outputs": [],
      "source": [
        "import os                 # For file and directory operations\n",
        "import glob               # For flexible file pattern matching (e.g., *.jpg in folders)\n",
        "from PIL import Image     # For opening, processing, and manipulating images\n",
        "\n",
        "# Hugging Face Transformers pipeline utility for high-level model tasks (like classification or zero-shot)\n",
        "from transformers import pipeline\n",
        "\n",
        "# Gradio: A lightweight library to build web-based UIs for ML models\n",
        "import gradio as gr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAw4r7wSlhJV",
        "outputId": "c97311de-e199-41aa-b5d9-ccf094ca2264"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "# === Initialize an Image Classification Pipeline Using Hugging Face Transformers ===\n",
        "\n",
        "image_classifier = pipeline(\n",
        "    \"image-classification\",           # Task type: image classification\n",
        "    model=\"microsoft/resnet-50\",      # Pretrained model: ResNet-50 trained on ImageNet-1k\n",
        "    framework=\"pt\"                    # Use PyTorch as the backend framework\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Step 2: Define the Prediction Function ===\n",
        "\n",
        "def classify_image(image):\n",
        "    # Ensure image is in RGB (some formats like .png may include alpha)\n",
        "    image = image.convert(\"RGB\")\n",
        "\n",
        "    # Run image through the classifier pipeline\n",
        "    outputs = image_classifier(image)\n",
        "\n",
        "    # Convert list of outputs to a dictionary: {label: score}\n",
        "    return {output[\"label\"]: float(output[\"score\"]) for output in outputs}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7861\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# === Step 3: Launch the Gradio Interface ===\n",
        "\n",
        "gr.Interface(\n",
        "    fn=classify_image,                      # The function to call on image input\n",
        "    inputs=gr.Image(type=\"pil\"),            # Accept a PIL image from upload or camera\n",
        "    outputs=gr.Label(num_top_classes=2),    # Display top 2 class probabilities as labeled bars\n",
        "    title=\"PCB Fault Detection\",            # Web app title\n",
        "    description=\"Upload a circuit board image to classify as Healthy or Faulty.\"  # App instructions\n",
        ").launch()                                  # Start the web server and open in browser\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "d07M7gj5lzF1",
        "outputId": "4e58a5db-b756-4a76-bd6b-23cf51e2a756"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "becb8e84f5574665ac43d424bcf572f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/756 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Cursor projects\\Assignment2\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\lille\\.cache\\huggingface\\hub\\models--timm--resnet50.a1_in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c5097a6d0c94a7fbaeb9ccd8a488295",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "# === Imports ===\n",
        "import gradio as gr                    # For creating the web interface\n",
        "from transformers import pipeline     # For loading pretrained transformer-compatible models\n",
        "from pathlib import Path               # For handling filesystem paths\n",
        "import os\n",
        "\n",
        "# === Load Example Images ===\n",
        "\n",
        "# Set the base dataset path\n",
        "base_path = Path(r\"D:\\Cursor projects\\Assignment2\\Dataset_Circuitboard\")\n",
        "\n",
        "# Manually gather one sample from each class (assuming 'Healthy' and 'Faulty' folders exist)\n",
        "healthy_folder = base_path / \"Healthy\"\n",
        "faulty_folder = base_path / \"Faulty\"\n",
        "\n",
        "# Collect one sample image path from each category\n",
        "healthy = next((healthy_folder / f for f in os.listdir(healthy_folder) if f.endswith(('.jpg', '.png', '.jpeg'))))\n",
        "faulty = next((faulty_folder / f for f in os.listdir(faulty_folder) if f.endswith(('.jpg', '.png', '.jpeg'))))\n",
        "\n",
        "# === Load Image Classification Pipeline ===\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"image-classification\",\n",
        "    model=\"timm/resnet50.a1_in1k\"  # Pretrained on ImageNet via TIMM\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify(image):\n",
        "    # Ensure the input image is in RGB format\n",
        "    # (some models don't handle grayscale or images with alpha channels well)\n",
        "    image = image.convert(\"RGB\")\n",
        "\n",
        "    # Run the image through the Hugging Face image classification pipeline\n",
        "    # This returns a list of predictions with labels and confidence scores\n",
        "    predictions = pipe(image)\n",
        "\n",
        "    # Return the top predicted label and its confidence score, formatted as a string\n",
        "    return f\"{predictions[0]['label']} ({predictions[0]['score']:.2f})\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7862\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# === Create and Launch a Gradio Interface ===\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=classify,                     # The prediction function to call when an image is uploaded\n",
        "    inputs=gr.Image(type=\"pil\"),     # Input component: an image, returned as a PIL object\n",
        "    outputs=\"text\",                  # Output type: plain text showing predicted label and score\n",
        "    title=\"Circuit Board Classifier\",       # Title shown at the top of the web UI\n",
        "    description=\"Upload a circuit board image to classify it.\",  # Helpful description below the title\n",
        "    examples=[[healthy], [faulty]]   # Preloaded image examples (optional, improves UX)\n",
        ")\n",
        "\n",
        "# === Start the App ===\n",
        "demo.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
